[{"title":"计算图上的微积分—反向传播","date":"2017-04-10T16:08:21.000Z","path":"2017/04/11/计算图上的微积分—反向传播/","text":"反向传播算法是在机器学习中应用十分广泛的算法，但很多人并未真正理解其重要性。这里会通过计算图来比较前向算法和反向算法的差异，从而展现反向传播的强大和优越之处。 1. 计算图计算图是很好的思考数学表达式的方法。例如式子$e=(a+b)*(b+1)$。有加法和乘法三个运算符，引入俩个中间变量$c$和$d$，这样每个函数的输出就都有一个变量了，于是有：$$c = a + b \\\\d = b + 1 \\\\e = c * d$$要产生计算图，使每个这些运算符和输入变量到节点中去。当一个节点的值是另一个节点的输入时，用一个箭头从这个节点指向另一个： 这种图在计算机科学中一直出现，尤其是谈到函数式程序的时候，与依赖图和调用图的概念非常接近，也同样是流行的深度学习框架Theano的核心概念。 可以设定输入变量为某些特定的值并通过计算图的节点来评估表达式。比如，设$a=2, b=1$： 2. 计算图上的求导要理解计算图中的求导，关键是理解边上的求导。如果$a$直接影响$c$，那它在什么程度影响呢？可以通过偏导数来评估，要理解这个图中的偏导，需要加法规则和乘法规则：$$\\frac{\\partial}{\\partial a}(a+b) = \\frac{\\partial a}{\\partial a} + \\frac{\\partial b}{\\partial a} = 1 \\\\\\frac{\\partial}{\\partial u}{uv} = u \\frac{\\partial v}{\\partial u} + v \\frac{\\partial u}{\\partial u} = v$$然后每个边的求导就是： 那非直连的两个节点是如何相互影响的呢？考虑$e$如何受$a$的影响。若以速度1改变$a$，$c$也会以速度1改变；接下来，$c$以1的速度改变会导致$e$以速度2变化。所以对于$a$，$e$以$1*2$的速率变化。 通用规则是将一个节点到另一个节点所有可能的路径相加，并将路径上的每条边的导数相乘起来。例如，求$e$对应于$b$的导数：$$\\frac{\\partial e}{\\partial b} = 1*2 + 1*3$$这解释了$b$如何通过$c$和$d$影响$e$。“所有路径相加”的规则是另一种考虑多元链式法则的方法。 3. 分解路径“所有路径相加”在可能路径数量上很容易导致组合爆炸的问题。 上面的图表中有三条从$X$到$Y$的路径，三条从$Y$到$Z$。若想要通过所有路径相加得到导数$\\frac{\\partial Z}{\\partial X}$，需要加上$3*3=9$条路径：$$\\frac{\\partial Z}{\\partial X} = \\alpha\\delta + \\alpha\\epsilon + \\alpha\\zeta + \\beta\\delta + \\beta\\epsilon + \\beta\\zeta + \\gamma\\delta + \\gamma\\epsilon + \\gamma\\zeta$$而且当图变复杂时路径数量很容易指数性增长；因此更好的方法是将它们因子分解：$$\\frac{\\partial Z}{\\partial X} = (\\alpha+\\beta+\\gamma)(\\delta+\\epsilon+\\zeta)$$这就是“前向模式微分”和“反向模式微分”的由来。它们通过分解路径来高效求和，在每个节点将路径回到一起的合并起来。前向模式积分从图的输入开始并向前移动知道终点；在每个节点上，它将所有进入的路径相加起来；每条这样的路径代表输入影响节点的一个方式；将它们求和就得到节点受输入影响的总的方式。它的导数是： 另一方面，反向模式微分从图的输出开始一直移动到开始。在每个节点上，它将所有源于节点的路径合并。 前向模式微分追踪一个输入如何影响每个节点，反向模式微分则追踪每个节点如何影响输出，也就是说，前向微分应用算子$\\frac{\\partial}{\\partial X}$到每个节点，而反向模式则应用算子$\\frac{\\partial Z}{\\partial}$到每个节点。 4. 计算胜利那为何每个人都关注反向模式微分呢？它有什么优势吗？考虑原始例子： 可以使用前向模式微分从$b$向上；可以得到每个节点相应于$b$的导数。 计算得到了$\\frac{\\partial e}{\\partial b}$，输出对应于于一个输入的导数。 如果使用反向模式从$e$向下呢？这会得到$e$对应于每个节点的导数： 计算得到了$\\frac{\\partial e}{\\partial a}$和$\\frac{\\partial e}{\\partial b}$，输出对应于所有输入的导数。 想象一个有百万输入的函数，前向模式微分需要贯穿百万次图来获得导数，而反向模式微分仅需一次。在训练神经网络时，将损失视为参数的函数，需要计算损失对应于所有参数的导数来使用梯度下降，因此，反向模式微分，也就是神经网络中的反向传播，可以有极大的加速。 5. 结论导数比想象得更廉价，这是这篇文章的主要教训，但事实上它们是非直觉的廉价，而愚蠢的人类不得不反复发觉它。还有其他的吗，当然。 反向传播也是理解导数如何流过一个模型的有用视角。这在推理为何一些模型难以优化时变得极端有益。经典的例子就是循环神经网络中的梯度弥散问题。 最后，有大量的算法教训从这些技术中获得。反向传播和前向模式微分使用一对强大的技巧（线性化和动态规划）来更高效得计算导数。","tags":[{"name":"machine learning","slug":"machine-learning","permalink":"http://yoursite.com/tags/machine-learning/"},{"name":"deep learning","slug":"deep-learning","permalink":"http://yoursite.com/tags/deep-learning/"}]},{"title":"RNN详解（一）","date":"2017-04-10T13:01:57.000Z","path":"2017/04/10/RNN详解1/","text":"RNN即循环神经网络，是在自然语言处理(NLP)和语音识别(SR)中应用非常广泛的一种模型。本文将会介绍RNN的原理以及相应的python代码实现。 1. RNN是什么RNN背后的思想是利用序列信息。在传统的神经网络中我们假设所有的输入（和输出）是相互独立的。但对很对任务而言并不成立。若想要预测句子中的下一个单词，最好知道它前面的单词。RNN之所以被称为循环是因为它们对序列中的每个元素执行相同的操作，而输出则依赖于前面的运算。另一种理解RNN的方式是它们有一个“内存”来获取迄今计算的信息。理论上RNN可以使用任意长度的信息，但实际上被限制到仅向后看几步。典型的RNN看起来这样： 上面的图片展示了RNN被展开为一个全网络，即写出了整个序列的网络。比如，如果我们关心的句子有5个单词，网络就会展开为一个5层网络，每层一个词。RNN计算的公式为： $x_t$是在时间$t$的输入。例如，$x_1$可能是句子中第二个词对应的一个独热向量。 $s_t$是在时间$t$的隐状态。它是网络的“记忆”。$s_t$基于前一个隐状态和当前输入计算：$s_t=f(Ux_t+Ws_{t-1})$，函数$f$通常非线性，比如tanh或ReLU。第一个要计算的隐变量$s_{-1}$通常初始化为全0。 $o_t$是时间$t$的输出。比如要预测一句话中的下个词，输出是一个在辞典上的概率向量：$o_t=softmax(Vs_t)$。 这里需要注意几件事： 可以认为隐状态$s_t​$是网络的记忆。$s_t​$获取所有前面时间发生的内容，输出$o_t​$仅基于时间$t​$的记忆。但在实际中会更复杂一些，因为$s_t​$通常并不能从前面太多步获取信息。 不同于传统的深度神经网络每一层的参数不同，RNN在所有时间步共享参数（上面的$U,V,W$）。这反应了每一步都执行相同的任务，仅仅不同的输入。这极大地减少了需要学习的参数量。 上面的图表中在每一步都有输出，但根据任务可能并不需要。比如，在预测句子的感情的时候我们仅关注最后的输出。同样，可能也不需要每一个时间步有输入。RNN的主要特征是隐状态。 2. 训练RNN训练RNN与训练传统神经网络类似。也使用后向传播算法，但有一些变化。因为网络中的参数被所有的时间步共享，每个输出的梯度不仅依赖于当前步的计算，也与前面步骤有关。比如，要计算$t=4$的梯度，可能需要回溯三步并将梯度相加。这被称为依时间反向传播(BPTT)。但是用BPTT训练的普通RNN在学习长期依赖时有问题，因为存在所谓的梯度消失/爆炸问题。有一些方法来解决这些问题，某些RNN（像LSTM）就是专门设计躲开这些问题的。 3. RNN扩展多年来研究者改进了更多精巧的RNN来解决普通RNN的问题。 双向RNN基于时间$t$的输出可能不仅依赖于序列前一个元素，还依赖于下一个元素的想法。比如，要预测序列中丢失的一个词语，你会想要观察左右两侧的上下文。双向RNN很简单，仅是两个RNN互相首尾堆叠。输出基于两个RNN的隐状态计算。 深度（双向）RNN与双向RNN类似，仅仅是在每一步有多层网络。在实践中有更强的学习能力（但也需要很多的训练数据）。 长短项记忆(LSTM)网络目前很流行，它与RNN并无根本上的不同结构，但使用不同的函数计算隐状态。LSTM中的记忆(memory)被称为单元(cell)，可以将其视为以前面状态$h_{t-1}$和当前输入$x_t$为输入的黑盒。这些单元内在决定记忆中保留（或清除）的信息。然后它们将前个状态、当前记忆和输入结合起来。事实证明这种单元可以非常高效地获取长期依赖。通过可以这篇文章了解更多。 接下来用python从头实现一个RNN，并用theano优化。 4. 语言模型我们的目标是用RNN建立一个语言模型。假设有$m$个单词组成的句子，语言模型可以预测（在给定数据集中）观察到这个句子的概率： $$P(w_1,\\dots,w_m)=\\prod_{i=1}^m P(w_i|w_1,\\dots,w_{i-1})$$即，一个句子的概率就是每个单词在给定其前面单词的概率的乘积。这为何会有效？ 首先，这样一个模型可以用作一个打分机制；然后，因我们可以预测一个词在给定其前面词的概率，就可以产生新的文本。这是一个生成式模型，Andrej Karpathy在这方面有一篇很好的文章。 注意上面等式中每个词的概率都以所有前面的词为条件；实际中会限制到仅看前面几个单词。 5. 训练数据与预处理训练语言模型需要文本来学习，可以从谷歌的BigQuery上下载15000条稍长的reddit评论。生成的文本可能听起来像reddit的评论。 标记化文本可以使我们以词为单位预测文本。使用nltk的word_tokenize和sent_tokenize函数完成。 剔除稀有词可以显著加快训练的速度，并且对于这样的词语也没有充足的上下文样例来学习怎样正确地使用。在代码中我们限制辞典到vocabulary_size个常见单词（这里设为8000，但可视情况改变）。将所有不再辞典中的单词替换为UNKNOW_TOKEN。单词UNKNOW_TOKEN也会包含在辞典中，并像其他词一样预测。当产生新文本时再将其替换，比如可以随机从不在辞典中的单词抽取，或者直到生成不含未知标签的句子。 添加特殊开始和结束标记在我们想学习哪些词倾向于开始或结束句子时可以发挥作用。我们添加特殊的SENTENCE_START和SENTENCE_END标记到每个句子。这使我们可以探求：给定首个SENTENCE_START，下一个词可能是什么（实际上的第一个词）？ 建立训练数据矩阵，因RNN的输入是向量，需要产生词到索引之间的映射，index_to_word和word_to_index。比如单词”friendly”可能索引是2001，一个训练样本的$x$可能看起来是$[0,179,341,416]$，其中0对应SENTENCE_START；对应的标签$y$可能是$[179,341,416,1]$。记住我们的目标是预测下一个单词，因此$y$就是$x$向量用SENTENCE_END移动一个位置。也就是说，单词179正确的预测是341，实际的下一个词。 123456789101112131415161718192021222324252627282930313233343536373839404142vocabulary_size = 8000unknown_token = \"UNKNOWN_TOKEN\"sentence_start_token = \"SENTENCE_START\"sentence_end_token = \"SENTENCE_END\"# Read the data and append SENTENCE_START and SENTENCE_END tokensprint \"Reading CSV file...\"with open('data/reddit-comments-2015-08.csv', 'rb') as f: reader = csv.reader(f, skipinitialspace=True) reader.next() # Split full comments into sentences sentences = itertools.chain(*[nltk.sent_tokenize(x[0].decode('utf-8').lower()) for x in reader]) # Append SENTENCE_START and SENTENCE_END sentences = [\"%s %s %s\" % (sentence_start_token, x, sentence_end_token) for x in sentences]print \"Parsed %d sentences.\" % (len(sentences))# Tokenize the sentences into wordstokenized_sentences = [nltk.word_tokenize(sent) for sent in sentences]# Count the word frequenciesword_freq = nltk.FreqDist(itertools.chain(*tokenized_sentences))print \"Found %d unique words tokens.\" % len(word_freq.items())# Get the most common words and build index_to_word and word_to_index vectorsvocab = word_freq.most_common(vocabulary_size-1)index_to_word = [x[0] for x in vocab]index_to_word.append(unknown_token)word_to_index = dict([(w,i) for i,w in enumerate(index_to_word)])print \"Using vocabulary size %d.\" % vocabulary_sizeprint \"The least frequent word in our vocabulary is '%s' and appeared %d times.\" % (vocab[-1][0], vocab[-1][1])# Replace all words not in our vocabulary with the unknown tokenfor i, sent in enumerate(tokenized_sentences): tokenized_sentences[i] = [w if w in word_to_index else unknown_token for w in sent] print \"\\nExample sentence: '%s'\" % sentences[0]print \"\\nExample sentence after Pre-processing: '%s'\" % tokenized_sentences[0] # Create the training dataX_train = np.asarray([[word_to_index[w] for w in sent[:-1]] for sent in tokenized_sentences])y_train = np.asarray([[word_to_index[w] for w in sent[1:]] for sent in tokenized_sentences]) 这是我们文本中一个真实的训练样例： 1234567x:SENTENCE_START what are n&apos;t you understanding about this ? ![0, 51, 27, 16, 10, 856, 53, 25, 34, 69] y:what are n&apos;t you understanding about this ? ! SENTENCE_END[51, 27, 16, 10, 856, 53, 25, 34, 69, 1] 6. 构建RNN考虑到矩阵乘法的工作原理，不能仅使用单词索引作为输出，这里用一个vocabulary_size维的独热(one-hot)向量表示单词，因此输入$x$就是一个矩阵，每个$x_t$是一个向量，这种转变会在神经网络的代码中实现。输出$o$也是同样的格式。每个$o_t$是vocabulary_size个元素的向量，每个元素代表那个词在句子中为下个词的概率。 RNN的公式概括起来是： $$s_t=tanh(Ux_t+Ws_{t-1})$$ $$o_t=softmax(Vs_t)$$ 写下矩阵和向量的维数通常很有用。假设字典长度$C=8000$，隐层规模是$H=100$。隐层可视为网络的记忆，规模越大越利于学习复杂的模式，但也会带来额外的计算。因此就有： $x_t \\in \\mathbb{R}^{8000}$ $o_t \\in \\mathbb{R}^{8000}$ $s_t \\in \\mathbb{R}^{100}$ $U \\in \\mathbb{R}^{100\\times 8000}$ $V \\in \\mathbb{R}^{8000\\times 100}$ $W \\in \\mathbb{R}^{100\\times 100}$ 这里的$x_t,o_t,s_t$都是列向量，需记住的是上面形式指数的第一个元素总是表示行数。 其中$U,V,W$是网络要从数据中学习的参数。因此，总共需要学习$2HC+H^2$个参数，这里是1610000。注意到$x_t$是独热向量，用$U$相乘等价于从$U$中选择一列。因此网络中最大的矩阵乘法就是$Vs_t$。 7. 初始化首先声明一个初始化参数的RNN类。初始化$U,V,W$参数比较棘手，并不能都初始为0，因为这样在网络层中会导致对称计算，必须随机生成。因合适的初始化对训练结果影响很大，所以在此领域已有很多研究。实践证明最佳的初始化依赖于激活函数，推介的方法是在区间$\\left[ -\\frac{1}{\\sqrt{n}}, \\frac{1}{\\sqrt{n}} \\right]$，其中$n$是来自上一层的接下来的连接的个数。但其实只要用小的随机值来初始化参数，通常效果都不错。 12345678910111213class RNNNumpy: def __init__(self, word_dim, hidden_dim=100, bptt_truncate=4): # Assign instance variables self.word_dim = word_dim self.hidden_dim = hidden_dim self.bptt_truncate = bptt_truncate # Randomly initialize the network parameters self.U = np.random.uniform(-np.sqrt(1./word_dim), np.sqrt(1./word_dim), (hidden_dim, word_dim)) self.V = np.random.uniform(-np.sqrt(1./hidden_dim), np.sqrt(1./hidden_dim), (word_dim, hidden_dim)) self.W = np.random.uniform(-np.sqrt(1./hidden_dim), np.sqrt(1./hidden_dim), (hidden_dim, hidden_dim)) 8. 前向传播接下来实现前向传播（预测单词概率）。 123456789101112131415161718def forward_propagation(self, x): # The total number of time steps T = len(x) # During forward propagation s saves all hidden states # Add one additional element for the initial hidden s = np.zeros((T+1, self.hidden_dim)) s[-1] = np.zeros(self.hidden_dim) # The variable o save the output at each time step o = np.zeros((T, self.word_dim)) # For each time step for t in np.arange(T): # Index U by x[t], the same as multiplying U with one-hot vector # 因x[t]是独热向量，所以U与x[t]的内积就相当于选取U中x[t]非零的那一列 s[t] = np.tanh(self.U[:, x[t]] + self.W.dot(s[t-1])) o[t] = softmax(self.V.dot(s[t])) return [o, s]RNNNumpy.forward_propagation = forward_propagation 不仅返回计算结果，也返回隐状态，后面会使用它们计算梯度。每个$o_t$是表示辞典中刺的概率，预测的下一个次就是概率最高的。 123456def predict(self, x): # Perform forward propagation and return index of highest score o, s = self.forward_propagation(x) return np.argmax(o, axis=1)RNNNumpy.predict = predict 9. 计算损失使用交叉熵损失作为损失函数$L$，目标是找到$U,V,W$为训练数据最小化损失函数。假设有$N$个训练样本（文本中的单词）和$C$类（字典的规模），则预测$o$和真实标签$y$所对应的损失就是：$$L(y,o) = -\\frac{1}{N} \\sum_{n \\in N} y_n \\log o_n$$对应的程序是： 12345678910111213141516171819202122def calculate_total_loss(self, x, y): L = 0 # For each sentence for i in np.arange(len(y)): o, s = self.forward_propagation(x[i]) # 那个o[array, list]的作用是array和list各自对应位置的元素组成二维索引 # 提取o中索引位置的值，共索引len(array)个，也就是得到o在原本应该是正确 # 答案词的位置，作用其实也相当于将正确词对应的独热向量与输出作内积 # 用在后面的测试与正确词原本应该对应的1的距离。 # 优化目标实际上就是使得预测的结果在正确的词上面最大 correct_word_predictions = o[np.arange(len(y[i])), y[i]] # Add to the loss based on how off they were L += -1 * np.sum(np.log(correct_word_predictions)) return Ldef calculate_loss(self, x, y): # Divide the total loss by the number of training examples N = np.sum(len(y_i) for y_i in y) return self.calculate_total_loss(x,y) / NRNNNumpy.calculate_total_loss = calculate_total_lossRNNNumpy.calculate_loss = calculate_loss 10. 依时间梯度下降这里将$o_t$表示为$\\hat{y}_t$，$L(y,o)$表示为$E(y,\\hat{y})$，于是有$$\\begin{aligned}E_t(y_t, \\hat{y}_t)&amp;= -y_{t} \\log \\hat{y}_{t} \\\\E(y, \\hat{y})&amp;=\\sum\\limits_{t} E_t(y_t,\\hat{y}_t) \\\\&amp; = -\\sum\\limits_{t} y_{t} \\log \\hat{y}_{t} \\end{aligned}$$其中$y_t$是当前步的正确单词，$\\hat{y}_t$是我们的预测，通常将整个序列（句子）视为一个训练样本，所以总的错误就是将每个时间步（单词）的错误相加起来。 我们的目标是计算损失对应于参数$U,V,W$的梯度，并通过SGD学习好的参数。对于一个训练样本，我们也将每个时间步的梯度相加$\\frac{\\partial{E}}{\\partial{W}}=\\sum_t \\frac{\\partial{E_t}}{\\partial{W}}$。使用链式法则计算这些梯度，以$E_3$为例：$$\\begin{aligned}\\frac{\\partial{E_3}}{\\partial{V}}&amp;= \\frac{\\partial{E_3}}{\\partial{\\hat{y}_3}} \\frac{\\partial{\\hat{y}_3}}{\\partial{V}} \\\\&amp;= \\frac{\\partial{E_3}}{\\partial{\\hat{y}_3}} \\frac{\\partial{\\hat{y}_3}}{\\partial{z_3}} \\frac{\\partial{z_3}}{\\partial{V}} \\\\&amp;= (\\hat{y}_3 - y_3) \\otimes s_3\\end{aligned}$$其中$z_3=Vs_3$，$\\otimes$表示两个向量的外积，可见$\\frac{\\partial{E_3}}{\\partial{V}}$仅依赖于当前时间步的值：$\\hat{y}_3, y_3, s_3$。但对$\\frac{\\partial{E_3}}{\\partial{W}}$则不同（对$U$而言也是这样）。写下链式规则，有$$\\frac{\\partial{E_3}}{\\partial{W}} = \\frac{\\partial{E_3}}{\\partial{\\hat{y}_3}} \\frac{\\partial{\\hat{y}_3}}{\\partial{s_3}} \\frac{\\partial{s_3}}{\\partial{W}}$$其中$s_3=tanh(Ux_t+Ws_2)$依赖于$s_2$，而$s_2$则依赖于$W$和$s_1$。所以在求$W$的导数时不能简单得将$s_2$取为常数，而需要再次使用链式法则，所以最后得到的是：$$\\begin{aligned}\\frac{\\partial E_3}{\\partial W}&amp;= \\sum\\limits_{k=0}^{3} \\frac{\\partial E_3}{\\partial \\hat{y}_3}\\frac{\\partial\\hat{y}_3}{\\partial s_3}\\frac{\\partial s_3}{\\partial s_k}\\frac{\\partial s_k}{\\partial W}\\\\\\end{aligned}$$将每一步对梯度的贡献相加。换句话说，因为$W$在每一步我们所关注的输出都被用到了，我们需要从$t=3$开始通过网络将梯度自始至终后向传播至$t=0$： 这恰与前向神经网络中标准的反向传播算法一样，关键的不同在于我们将$W$的梯度在每个时间步上相加（前向神经网络则是每一层正向传播，所以一个在时间维度上是深度网络，另一个则是空间维度上的）。传统的神经网络在层之间并不共享参数，所以无需求和。对于展开的循环神经网络，BPTT是标准反向传播的一个非常别致的名称。就像反向传播可以定义一个delta向量来传递后面部分，比如$\\delta_2^{(3)}=\\frac{\\partial{E_3}}{\\partial{z_2}}=\\frac{\\partial{E_3}}{\\partial{s_3}}\\frac{\\partial{s_3}}{\\partial{s_2}}\\frac{\\partial{s_2}}{\\partial{z_2}}$，其中$z_2=Ux_2+Ws_1$，同样的公式也适用。 11. 用SGD和BPTT训练RNN寻找最小化训练数据上总损失的参数$U,V,W$最通用的方法是SGD，也就是随机梯度下降。已经有很多研究探索优化SGD的方法，包括批处理、并行和自适应学习率。这里只实现一个简单的SGD。 这里使用依时间后向传播(BPTT)算法来计算梯度。因为参数被神经网络的所有时间步所共享，因此每个输出的梯度不仅取决于当前步，还有前面的步骤，使用链式规则来计算。 12345678910111213141516171819202122232425def bptt(self, x, y): T = len(y) # Perform forward propagation o, s = self.forward_propagation(x) # Accumulate the gradients in these variables dLdU = np.zeros(self.U.shape) dLdV = np.zeros(self.V.shape) dLdW = np.zeros(self.W.shape) delta_o = o delta_o[np.arange(len(y)), y] -= 1. # For each output backwards... for t in np.arange(T)[::-1]: dLdV += np.outer(delta_o[t], s[t].T) # Initial delta calculation delta_t = self.V.T.dot(delta_o[t]) * (1 - (s[t]**2)) # Backpropagation through time for bptt_step in np.arange(max(0, t-self.bptt_truncate), t+1)[::-1]: print \"Backpropagation step t=%d bptt step=%d\" % (t, bptt_step) dLdW += np.outer(delta_t, s[bptt_step-1]) dLdU[:, x[bptt_step]] += delta_t # Update delta for next step delta_t = self.W.T.dot(delta_t) * (1-s[bptt_step-1]**2) return [dLdU, dLdV, dLdW]RNNNumpy.bptt = bptt 12. 梯度检验无论何时实施反向传播，最好也实施梯度验证，那是核实你的实现是否正确的一种方法，背后的思想是参数的导数等于在此点的斜率，这个可以通过稍许改变参数然后用改变去除得到：$$\\frac{\\partial{L}}{\\partial{\\theta}} \\approx \\lim_{h \\to 0}\\frac{J(\\theta+h)-J(\\theta-h)}{2h}$$然后比较反向传播得到的梯度和上面式子得到的梯度，相差不大即可；为减少运算代价，最好是在一个小一点的字典模型上验证： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849def gradient_check(self, x, y, h=0.001, error_threshold=0.01): # Calculate the gradients using backpropagation. bptt_gradients = model.bptt(x, y) # List of all parameters we want to check. model_parameters = ['U', 'V', 'W'] # Gradient check for each parameter for pidx, pname in enumerate(model_parameters): # Get the actual parameter value from the mode parameter = operator.attrgetter(pname)(self) print \"Performing gradient check for parameter %s with size %d.\" % ( pname, np.prod(parameter.shape)) # Iterate over each element of the parameter matrix it = np.nditer(parameter, flags=['multi_index'], op_flags=['readwrite']) while not it.finished: ix = it.multi_index # Save the original value so we can reset it later original_value = parameter[ix] # Estimate the gradient using (f(x+h) - f(x-h))/(2*h) parameter[ix] = original_value + h gradplus = model.calculate_total_loss([x],[y]) parameter[ix] = original_value - h gradminus = model.calculate_total_loss([x],[y]) estimated_gradient = (gradplus - gradminus)/(2*h) # Reset parameter to original value parameter[ix] = original_value # The gradient for this parameter calculated using backpropagation backprop_gradient = bptt_gradients[pidx][ix] # calculate The relative error: (|x - y|/(|x| + |y|)) relative_error = np.abs(backprop_gradient - estimated_gradient)/( np.abs(backprop_gradient) + np.abs(estimated_gradient)) # If the error is to large fail the gradient check if relative_error &gt; error_threshold: print \"Gradient Check ERROR: parameter=%s ix=%s\" % (pname, ix) print \"+h Loss: %f\" % gradplus print \"-h Loss: %f\" % gradminus print \"Estimated_gradient: %f\" % estimated_gradient print \"Backpropagation gradient: %f\" % backprop_gradient print \"Relative Error: %f\" % relative_error return it.iternext() print \"Gradient check for parameter %s passed.\" % (pname)RNNNumpy.gradient_check = gradient_check# Use a smaller vocabulary size for checking.grad_check_vocab_size = 100np.random.seed(10)model = RNNNumpy(grad_check_vocab_size, 10, bptt_truncate=1000)model.gradient_check([0,1,2,3], [1,2,3,4]) 13. SGD实现能够计算梯度后，就可以实现SGD了。可以分两步来实现： 一个sdg_step函数计算梯度并执行一个批次的更新。 12345678910# Perform one step SGDdef numpy_sdg_step(self, x, y, learning_rate): # Calculate the gradients dLdU, dLdV, dLdW = self.bptt(x, y) # Change parameters according to gradients and learning rate self.U -= learning_rate * dLdU self.V -= learning_rate * dLdV self.W -= learning_rate * dLdWRNNNumpy.sgd_step = numpy_sdg_step 一个外层循环来迭代训练集并调整学习率。 123456789101112131415161718192021222324252627282930# Outer SGD Lop# - model: The RNN model instance# - X_train: The training data set# - y_train: the training data labels# - learning_rate: Initial lerning rate for SGD# - nepoch: Number of times to iterate through the complete dataset# - evaluate_loss_after: Evaluate the loss after this many epochsdef train_with_sgd(model, X_train, y_train, learning_rate=0.005, npoch=100, evaluate_loss_after=5): # Keep track of the losses to plot them losses = [] num_examples_seen = 0 for epoch in range(nepoch): # Optionally evaluate the loss if(epoch % evaluate_loss_after == 0): loss = model.calculate_loss(X_train, y_train) losses.append((num_examples_seen, loss)) time = datetime.now().strftime('%Y-%m-%d %H:%M:%S') print \"%s: LOss after num_examples_seen=%d epoch=%d: %f\" % ( time,num_examples_seen, epoch, loss) # Adjust the learning rate if loss increases if(len(losses) &gt; 1 and losses[-1][1] &gt; losses[-2][1]): learning_rate = learning_rate * 0.5 print \"Setting learning rate to %f\" % learning_rate sys.stdout.flush() # For each training examples for i in range(len(y_train)): # One SGD step model.sgd_step(X_trian[i], y_train[i], learning_rate) num_examples_seen += 1 但这样的实现执行起来很费时间，有很多种方法来加速代码的运行，包括层次softmax或者增加一个投影层来避免大矩阵乘法。这里使用GPU来加速。 14. 使用Theano和GPU来训练网络15. 生成文本得到模型后就可以使用它来生成新文本： 123456789101112131415161718192021222324def generate_sentence(model): # Start the sentence with the start token new_sentence = [word_to_index[sentence_start_token]] # Repeat unitl get an end token while not new_sentence[-1] == word_to_index[sentence_end_token]: next_word_probs = model.forward_propagation(new_sentence) sampled_word = word_to_index[unknown_token] # Avoid to sample unknown tokens while sampled_word == word_to_index[unknown_token]: samples = np.random.multinomial(1, next_word_probs[-1]) sampled_word = np.argmax(samples) new_sentence.append(sampled_word) sentence_str = [index_to_word[x] for x in new_sentence[1:-1]] return sentence_strnum_sentences = 10senten_min_length = 7for i in range(num_sentences): sent = [] # To get long sentences while len(sent) &lt; senten_min_length: sent = generate_sentence(model) print \" \".join(sent) 模型成功地学习了句法，但并不通顺或者有语法问题。主要是因为普通RNN无法学得相隔几步远的单词之间的依赖。","tags":[{"name":"deep learning","slug":"deep-learning","permalink":"http://yoursite.com/tags/deep-learning/"},{"name":"NLP","slug":"NLP","permalink":"http://yoursite.com/tags/NLP/"}]},{"title":"配置数学公式环境","date":"2017-04-10T12:14:36.000Z","path":"2017/04/10/配置数学公式环境/","text":"要在hexo中用markdown写出数学公式，需要安装mathjax插件，可通过npm直接安装 要在hexo中用markdown写出数学公式，需要安装mathjax的插件。执行下面的代码：1$ npm install hexo-math --save 有些教程中还写了需要在_cimfig.yml文件中配置plugins，但实测不用配置直接就是能用的。下面就可以用latex的语法在markdown文件中协数学公式了：$\\alpha = \\beta + \\gamma$。123$$\\frac&#123;\\partial E\\_3&#125;&#123;\\partial W&#125; = \\sum\\_&#123;k=0&#125;^3 \\frac&#123;\\partial E\\_3&#125;&#123;\\partial \\hat&#123;y&#125;\\-3&#125;$$ 显示为$$\\frac{\\partial E_3}{\\partial W} = \\sum_{k=0}^3 \\frac{\\partial E_3}{\\partial \\hat{y}_3}$$但这样就会在用一些像_这样的特殊符号的时候就会出现问题，比较好的解决方法是：1234567&#123;% math %&#125;\\begin&#123;aligned&#125;\\dot&#123;x&#125; &amp; = \\sigma(y-x) \\\\\\dot&#123;y&#125; &amp; = \\rho x - y - xz \\\\\\dot&#123;z&#125; &amp; = -\\beta z + xy\\end&#123;aligned&#125;&#123;% endmath %&#125; 显示为$$\\begin{aligned} \\dot{x} &amp; = \\sigma(y-x) \\\\ \\dot{y} &amp; = \\rho x - y - xz \\\\ \\dot{z} &amp; = -\\beta z + xy \\end{aligned}$$","tags":[{"name":"hexo","slug":"hexo","permalink":"http://yoursite.com/tags/hexo/"}]}]